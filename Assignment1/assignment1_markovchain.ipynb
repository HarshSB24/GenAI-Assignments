{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00353826",
   "metadata": {},
   "source": [
    "# Text Generator Using Markov Chains\n",
    "\n",
    "## Assignment 1 - GenAI\n",
    "\n",
    "This notebook implements a simple text generator using Markov Chains. A Markov Chain is a stochastic model that describes a sequence of possible events where the probability of each event depends only on the state attained in the previous event.\n",
    "\n",
    "### How it works:\n",
    "1. **Training**: Analyze input text to build a probability model\n",
    "2. **State Transitions**: Track which words follow other words\n",
    "3. **Generation**: Use the model to generate new text based on learned patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee335a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1cd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3de1a",
   "metadata": {},
   "source": [
    "## 2. Markov Chain Text Generator Class\n",
    "\n",
    "The `MarkovChain` class implements:\n",
    "- **Training**: Builds transition probabilities from input text\n",
    "- **Text Generation**: Creates new text based on learned patterns\n",
    "- **Order (n-gram)**: Controls context size (default is bigram - 2 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e84e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovChain:\n",
    "    \"\"\"\n",
    "    A simple Markov Chain text generator.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    order : int\n",
    "        The order of the Markov chain (n-gram size). Default is 1 (bigram).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, order=1):\n",
    "        self.order = order\n",
    "        self.model = defaultdict(list)\n",
    "        self.start_words = []\n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Tokenize text into words.\"\"\"\n",
    "        # Remove extra whitespace and split into words\n",
    "        text = re.sub(r'\\s+', ' ', text.strip())\n",
    "        words = text.split()\n",
    "        return words\n",
    "    \n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Train the Markov chain on input text.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        text : str\n",
    "            The training text corpus\n",
    "        \"\"\"\n",
    "        words = self.tokenize(text)\n",
    "        \n",
    "        if len(words) < self.order + 1:\n",
    "            raise ValueError(f\"Text too short for order {self.order}\")\n",
    "        \n",
    "        # Build the model\n",
    "        for i in range(len(words) - self.order):\n",
    "            # Create state (current word(s))\n",
    "            if self.order == 1:\n",
    "                state = words[i]\n",
    "            else:\n",
    "                state = tuple(words[i:i + self.order])\n",
    "            \n",
    "            # Next word\n",
    "            next_word = words[i + self.order]\n",
    "            \n",
    "            # Add transition\n",
    "            self.model[state].append(next_word)\n",
    "        \n",
    "        # Store possible starting states\n",
    "        if self.order == 1:\n",
    "            self.start_words = [words[i] for i in range(len(words) - self.order)]\n",
    "        else:\n",
    "            self.start_words = [tuple(words[i:i + self.order]) \n",
    "                               for i in range(len(words) - self.order)]\n",
    "    \n",
    "    def generate(self, length=50, start_word=None):\n",
    "        \"\"\"\n",
    "        Generate text using the trained Markov chain.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        length : int\n",
    "            Number of words to generate\n",
    "        start_word : str or tuple\n",
    "            Starting word(s). If None, chosen randomly.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        str : Generated text\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not trained. Call train() first.\")\n",
    "        \n",
    "        # Choose starting state\n",
    "        if start_word is None:\n",
    "            current_state = random.choice(self.start_words)\n",
    "        else:\n",
    "            current_state = start_word if self.order > 1 else start_word\n",
    "        \n",
    "        # Initialize result\n",
    "        if self.order == 1:\n",
    "            result = [current_state]\n",
    "        else:\n",
    "            result = list(current_state)\n",
    "        \n",
    "        # Generate words\n",
    "        for _ in range(length - self.order):\n",
    "            if current_state not in self.model:\n",
    "                # If we hit a dead end, start from a random state\n",
    "                current_state = random.choice(self.start_words)\n",
    "                if self.order == 1:\n",
    "                    result.append(current_state)\n",
    "                else:\n",
    "                    result.extend(list(current_state))\n",
    "            \n",
    "            # Choose next word based on current state\n",
    "            next_word = random.choice(self.model[current_state])\n",
    "            result.append(next_word)\n",
    "            \n",
    "            # Update state\n",
    "            if self.order == 1:\n",
    "                current_state = next_word\n",
    "            else:\n",
    "                current_state = tuple(list(current_state)[1:] + [next_word])\n",
    "        \n",
    "        return ' '.join(result)\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        \"\"\"Return statistics about the trained model.\"\"\"\n",
    "        total_states = len(self.model)\n",
    "        total_transitions = sum(len(v) for v in self.model.values())\n",
    "        avg_transitions = total_transitions / total_states if total_states > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'total_states': total_states,\n",
    "            'total_transitions': total_transitions,\n",
    "            'avg_transitions_per_state': avg_transitions,\n",
    "            'order': self.order\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04783d0a",
   "metadata": {},
   "source": [
    "## 3. Sample Training Text\n",
    "\n",
    "Let's use some sample text to train our model. You can replace this with any text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30cdd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training text loaded!\n",
      "Text length: 1210 characters\n",
      "Word count: 160 words\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "Artificial intelligence is transforming the world. Machine learning algorithms can learn from data.\n",
    "Deep learning is a subset of machine learning. Neural networks are inspired by the human brain.\n",
    "Natural language processing helps computers understand human language. Computer vision enables machines to see.\n",
    "Artificial intelligence can solve complex problems. Machine learning models need training data.\n",
    "Deep learning models require large amounts of data. Neural networks consist of layers of neurons.\n",
    "Natural language processing is used in chatbots. Computer vision is used in autonomous vehicles.\n",
    "The future of artificial intelligence is bright. Machine learning is revolutionizing many industries.\n",
    "Deep learning has achieved remarkable results. Neural networks can recognize patterns in data.\n",
    "Natural language processing improves human-computer interaction. Computer vision technology is advancing rapidly.\n",
    "Artificial intelligence will continue to evolve. Machine learning techniques are becoming more sophisticated.\n",
    "Deep learning frameworks make development easier. Neural networks can be trained on GPUs.\n",
    "Natural language processing models understand context. Computer vision systems can detect objects.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Training text loaded!\")\n",
    "print(f\"Text length: {len(sample_text)} characters\")\n",
    "print(f\"Word count: {len(sample_text.split())} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0063eb47",
   "metadata": {},
   "source": [
    "## 4. Example 1: Order-1 Markov Chain (Bigram)\n",
    "\n",
    "In a first-order Markov chain, each word depends only on the previous word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02a48d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Statistics:\n",
      "  Order: 1\n",
      "  Unique states: 93\n",
      "  Total transitions: 159\n",
      "  Average transitions per state: 1.71\n",
      "\n",
      "============================================================\n",
      "Generated Text (Order-1):\n",
      "============================================================\n",
      "\n",
      "Example 1:\n",
      "problems. Machine learning models understand context. Computer vision is advancing rapidly. Artificial intelligence is used in chatbots. Computer vision enables machines to evolve. Machine learning models need training data. Deep\n",
      "\n",
      "Example 2:\n",
      "data. Deep learning techniques are becoming more sophisticated. Deep learning techniques are inspired by the human brain. Natural language processing is used in autonomous vehicles. The future of layers of\n",
      "\n",
      "Example 3:\n",
      "development easier. Neural networks consist of data. Deep learning models need training data. Deep learning techniques are becoming more sophisticated. Deep learning is transforming the world. Machine learning has achieved\n"
     ]
    }
   ],
   "source": [
    "# Create and train Order-1 Markov Chain\n",
    "markov_order1 = MarkovChain(order=1)\n",
    "markov_order1.train(sample_text)\n",
    "\n",
    "# Display statistics\n",
    "stats = markov_order1.get_statistics()\n",
    "print(\"Model Statistics:\")\n",
    "print(f\"  Order: {stats['order']}\")\n",
    "print(f\"  Unique states: {stats['total_states']}\")\n",
    "print(f\"  Total transitions: {stats['total_transitions']}\")\n",
    "print(f\"  Average transitions per state: {stats['avg_transitions_per_state']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generated Text (Order-1):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate multiple examples\n",
    "for i in range(3):\n",
    "    generated = markov_order1.generate(length=30)\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73489415",
   "metadata": {},
   "source": [
    "## 5. Example 2: Order-2 Markov Chain (Trigram)\n",
    "\n",
    "In a second-order Markov chain, each word depends on the previous two words, creating more coherent text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa4922e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Statistics:\n",
      "  Order: 2\n",
      "  Unique states: 131\n",
      "  Total transitions: 158\n",
      "  Average transitions per state: 1.21\n",
      "\n",
      "============================================================\n",
      "Generated Text (Order-2):\n",
      "============================================================\n",
      "\n",
      "Example 1:\n",
      "revolutionizing many industries. Deep learning is revolutionizing many industries. Deep learning has achieved remarkable results. Neural networks can be trained on GPUs. Natural language processing is used in chatbots. Computer\n",
      "\n",
      "Example 2:\n",
      "understand context. Computer vision technology is advancing rapidly. Artificial intelligence can solve complex problems. Machine learning techniques are becoming more sophisticated. Deep learning frameworks make development easier. Neural networks can\n",
      "\n",
      "Example 3:\n",
      "language processing improves human-computer interaction. Computer vision technology is advancing rapidly. Artificial intelligence is transforming the world. Machine learning algorithms can learn from data. Deep learning has achieved remarkable results.\n"
     ]
    }
   ],
   "source": [
    "# Create and train Order-2 Markov Chain\n",
    "markov_order2 = MarkovChain(order=2)\n",
    "markov_order2.train(sample_text)\n",
    "\n",
    "# Display statistics\n",
    "stats = markov_order2.get_statistics()\n",
    "print(\"Model Statistics:\")\n",
    "print(f\"  Order: {stats['order']}\")\n",
    "print(f\"  Unique states: {stats['total_states']}\")\n",
    "print(f\"  Total transitions: {stats['total_transitions']}\")\n",
    "print(f\"  Average transitions per state: {stats['avg_transitions_per_state']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generated Text (Order-2):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate multiple examples\n",
    "for i in range(3):\n",
    "    generated = markov_order2.generate(length=30)\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b376c8",
   "metadata": {},
   "source": [
    "## 6. Interactive Text Generation\n",
    "\n",
    "Generate text with custom parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff69f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 40 words starting with 'Artificial'...\n",
      "\n",
      "Order-1 Generation:\n",
      "------------------------------------------------------------\n",
      "Artificial intelligence is used in chatbots. Computer vision enables machines to evolve. Machine learning models understand human brain. Natural language processing models require large amounts of machine learning. Neural networks are becoming more sophisticated. Deep learning is used in chatbots.\n",
      "\n",
      "============================================================\n",
      "\n",
      "Order-2 Generation:\n",
      "------------------------------------------------------------\n",
      "Artificial intelligence will continue to evolve. Machine learning models require large amounts of data. Neural networks consist of layers of neurons. Natural language processing improves human-computer interaction. Computer vision is used in chatbots. Computer vision technology is advancing rapidly. Artificial\n"
     ]
    }
   ],
   "source": [
    "# Customize these parameters\n",
    "WORD_COUNT = 40\n",
    "START_WORD = \"Artificial\"  # or None for random start\n",
    "\n",
    "print(f\"Generating {WORD_COUNT} words starting with '{START_WORD}'...\\n\")\n",
    "\n",
    "# Generate with Order-1\n",
    "print(\"Order-1 Generation:\")\n",
    "print(\"-\" * 60)\n",
    "text1 = markov_order1.generate(length=WORD_COUNT, start_word=START_WORD)\n",
    "print(text1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Generate with Order-2\n",
    "print(\"Order-2 Generation:\")\n",
    "print(\"-\" * 60)\n",
    "# For order-2, we need a tuple of 2 words\n",
    "if START_WORD:\n",
    "    # Find a valid starting bigram that starts with START_WORD\n",
    "    valid_starts = [state for state in markov_order2.start_words \n",
    "                   if state[0] == START_WORD]\n",
    "    if valid_starts:\n",
    "        start_state = random.choice(valid_starts)\n",
    "        text2 = markov_order2.generate(length=WORD_COUNT, start_word=start_state)\n",
    "    else:\n",
    "        text2 = markov_order2.generate(length=WORD_COUNT)\n",
    "else:\n",
    "    text2 = markov_order2.generate(length=WORD_COUNT)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7634cef",
   "metadata": {},
   "source": [
    "## 7. Train on Your Own Text\n",
    "\n",
    "You can train the model on any text you want. Replace the text below with your own corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f281102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Model Statistics:\n",
      "{'total_states': 46, 'total_transitions': 63, 'avg_transitions_per_state': 1.3695652173913044, 'order': 1}\n",
      "\n",
      "============================================================\n",
      "Generated Text from Custom Model:\n",
      "============================================================\n",
      "\n",
      "Example 1:\n",
      "developers love Python has excellent community support. AI projects. Python for its simplicity. Python is a high-level programming paradigms. Web developers build applications with Python has\n",
      "\n",
      "Example 2:\n",
      "and maintainable. Machine learning engineers prefer Python for AI projects. Python for AI projects. Python is easy to learn and powerful. Many developers love Python\n"
     ]
    }
   ],
   "source": [
    "# Example: Train on a different text corpus\n",
    "custom_text = \"\"\"\n",
    "Python is a high-level programming language. Python is easy to learn and powerful.\n",
    "Many developers love Python for its simplicity. Python has a vast ecosystem of libraries.\n",
    "Data science professionals use Python extensively. Python supports multiple programming paradigms.\n",
    "Web developers build applications with Python frameworks. Python code is readable and maintainable.\n",
    "Machine learning engineers prefer Python for AI projects. Python has excellent community support.\n",
    "\"\"\"\n",
    "\n",
    "# Create new model and train\n",
    "custom_markov = MarkovChain(order=1)\n",
    "custom_markov.train(custom_text)\n",
    "\n",
    "print(\"Custom Model Statistics:\")\n",
    "print(custom_markov.get_statistics())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generated Text from Custom Model:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i in range(2):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(custom_markov.generate(length=25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc690f",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "### Key Observations:\n",
    "\n",
    "1. **Order-1 (Bigram)**: \n",
    "   - Generates text based on single word context\n",
    "   - More random and diverse output\n",
    "   - May produce less coherent sentences\n",
    "\n",
    "2. **Order-2 (Trigram)**:\n",
    "   - Uses two-word context for predictions\n",
    "   - More coherent and structured output\n",
    "   - Better captures phrase patterns\n",
    "\n",
    "3. **Trade-offs**:\n",
    "   - Higher order → More coherent but needs more training data\n",
    "   - Lower order → More creative but less structured\n",
    "\n",
    "### Applications:\n",
    "- Text generation and completion\n",
    "- Creative writing assistance\n",
    "- Chatbot responses\n",
    "- Data augmentation\n",
    "- Style mimicry\n",
    "\n",
    "### Limitations:\n",
    "- No long-term context memory\n",
    "- Requires substantial training data\n",
    "- May reproduce training data verbatim\n",
    "- No semantic understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d7586",
   "metadata": {},
   "source": [
    "## 9. Extensions and Improvements\n",
    "\n",
    "Try these enhancements:\n",
    "\n",
    "1. **Load text from files**: Train on books, articles, or documents\n",
    "2. **Sentence-aware generation**: Start/end at sentence boundaries\n",
    "3. **Temperature parameter**: Control randomness in word selection\n",
    "4. **Character-level models**: Generate text character by character\n",
    "5. **Visualization**: Show state transition graphs\n",
    "6. **Save/Load models**: Persist trained models for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae678bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common word transitions (Order-1 Model):\n",
      "============================================================\n",
      "1. 'learning' → 8 transitions\n",
      "   Most common next words: [('is', 2), ('models', 2), ('algorithms', 1)]\n",
      "\n",
      "2. 'is' → 7 transitions\n",
      "   Most common next words: [('used', 2), ('transforming', 1), ('a', 1)]\n",
      "\n",
      "3. 'can' → 5 transitions\n",
      "   Most common next words: [('learn', 1), ('solve', 1), ('recognize', 1)]\n",
      "\n",
      "4. 'of' → 5 transitions\n",
      "   Most common next words: [('machine', 1), ('data.', 1), ('layers', 1)]\n",
      "\n",
      "5. 'intelligence' → 4 transitions\n",
      "   Most common next words: [('is', 2), ('can', 1), ('will', 1)]\n",
      "\n",
      "6. 'Machine' → 4 transitions\n",
      "   Most common next words: [('learning', 4)]\n",
      "\n",
      "7. 'data.' → 4 transitions\n",
      "   Most common next words: [('Deep', 2), ('Neural', 1), ('Natural', 1)]\n",
      "\n",
      "8. 'Deep' → 4 transitions\n",
      "   Most common next words: [('learning', 4)]\n",
      "\n",
      "9. 'Neural' → 4 transitions\n",
      "   Most common next words: [('networks', 4)]\n",
      "\n",
      "10. 'networks' → 4 transitions\n",
      "   Most common next words: [('can', 2), ('are', 1), ('consist', 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example Extension: Visualize most common transitions\n",
    "print(\"Most common word transitions (Order-1 Model):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get top 10 states with most transitions\n",
    "state_counts = [(state, len(transitions)) \n",
    "                for state, transitions in markov_order1.model.items()]\n",
    "state_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (state, count) in enumerate(state_counts[:10], 1):\n",
    "    next_words = Counter(markov_order1.model[state])\n",
    "    top_next = next_words.most_common(3)\n",
    "    print(f\"{i}. '{state}' → {count} transitions\")\n",
    "    print(f\"   Most common next words: {top_next}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e4b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
